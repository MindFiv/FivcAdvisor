{
  "id": "snapshot_1760066600647_2b1mw6gky",
  "approvalId": "approval_1760065893252_8a8htz55l",
  "approvalTitle": "Tech Steering Document - FivcAdvisor Technology Stack and Architecture",
  "version": 2,
  "timestamp": "2025-10-10T03:23:20.647Z",
  "trigger": "approved",
  "status": "pending",
  "content": "# Technology Stack\n\n## Project Type\n\nFivcAdvisor is a **multi-interface AI agent system** that combines:\n- **CLI Tool** - Command-line interface for direct agent interaction\n- **Web Application** - Streamlit-based interactive chat interface\n- **Python Library** - Reusable components for agent and tool management\n\n## Core Technologies\n\n### Primary Language(s)\n- **Language**: Python 3.10+\n- **Runtime**: CPython (standard Python interpreter)\n- **Language-specific tools**: \n  - **Package Manager**: uv (recommended), pip (fallback)\n  - **Build System**: setuptools via pyproject.toml\n  - **Lock File**: uv.lock for reproducible builds\n\n### Key Dependencies/Libraries\n\n**Agent Framework:**\n- **strands-agents** (>=1.9.1): Core AI agent framework providing Agent, Task, Crew, and Flow abstractions\n- **strands-agents-tools** (>=0.2.8): Pre-built tools library for agent capabilities\n\n**LLM Integration:**\n- **openai** (>=1.109.1): OpenAI API client for GPT models\n- **Ollama support**: Via strands.models.ollama for local LLM deployment\n\n**Web Interface:**\n- **streamlit** (>=1.49.1): Modern web UI framework with async support and real-time updates\n\n**CLI & Terminal:**\n- **typer** (>=0.12.3): Modern CLI framework with type hints\n- **rich** (>=13.7.1): Rich terminal formatting and output\n\n**Data & Validation:**\n- **pydantic** (>=2.7.0): Data validation and settings management with type safety\n- **PyYAML** (>=6.0.1): YAML configuration file parsing\n\n**Vector Database & Embeddings:**\n- **chromadb** (>=1.1.0): Vector database for semantic tool search and retrieval\n- **langchain-text-splitters** (>=0.3.11): Text processing and chunking utilities\n\n**HTTP & Networking:**\n- **httpx** (>=0.28.1): Modern async HTTP client\n\n**Configuration:**\n- **python-dotenv** (>=1.0.1): Environment variable management from .env files\n\n**Tool Protocol:**\n- **MCP (Model Context Protocol)**: Dynamic tool loading via stdio and SSE clients\n- **mcp library**: Integrated via strands.tools.mcp for MCPClient support\n\n**Development Dependencies:**\n- **pytest** (>=8.2.0): Testing framework\n- **pytest-asyncio** (>=0.21.0): Async test support\n- **pytest-cov** (>=4.1.0): Code coverage reporting\n- **ruff** (>=0.4.0, <0.6): Fast Python linter and formatter\n\n### Application Architecture\n\n**Modular Plugin-Based Architecture:**\n\n```\n┌─────────────────────────────────────────────────────────┐\n│                  Interface Layer                         │\n│         (CLI via Typer / Web via Streamlit)             │\n└────────────────────┬────────────────────────────────────┘\n                     │\n┌────────────────────▼────────────────────────────────────┐\n│                  Agent Layer                             │\n│  - Agent Creators (decorator-based factories)           │\n│  - Agent Types (Generic, Companion, Consultant, etc.)   │\n│  - Conversation Management                               │\n└────────────────────┬────────────────────────────────────┘\n                     │\n┌────────────────────▼────────────────────────────────────┐\n│                  Tool Layer                              │\n│  - ToolsRetriever (semantic search)                     │\n│  - ToolsConfig (MCP integration)                        │\n│  - Built-in Tools + MCP Tools                           │\n└────────────────────┬────────────────────────────────────┘\n                     │\n┌────────────────────▼────────────────────────────────────┐\n│                  Model Layer                             │\n│  - Model Factories (default, chat, reasoning, coding)   │\n│  - Provider Abstraction (OpenAI, Ollama)                │\n└────────────────────┬────────────────────────────────────┘\n                     │\n┌────────────────────▼────────────────────────────────────┐\n│              Infrastructure Layer                        │\n│  - Settings Management (YAML + .env)                    │\n│  - Embeddings (ChromaDB)                                │\n│  - Utilities (lazy loading, directories)                │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Key Architectural Patterns:**\n- **Factory Pattern**: Agent creators with `@agent_creator` decorator\n- **Lazy Loading**: Deferred initialization for configuration and resources\n- **Plugin System**: Dynamic tool registration and discovery\n- **Async/Await**: Non-blocking execution in web interface\n- **Separation of Concerns**: Clear boundaries between agents, tools, models, and UI\n\n### Data Storage\n\n- **Primary storage**: File system (YAML configs, .env files, pickle for REPL state)\n- **Vector Database**: ChromaDB for tool embeddings and semantic search\n  - In-memory or persistent mode\n  - Stores tool descriptions and metadata\n  - Enables similarity-based tool retrieval\n- **Session State**: Streamlit session state for web UI persistence\n- **Data formats**: \n  - YAML for configuration (settings.yaml, mcp.yaml)\n  - JSON for structured data exchange\n  - Pickle for Python object serialization (REPL state)\n\n### External Integrations\n\n**APIs:**\n- **OpenAI API**: GPT models for agent intelligence\n- **Ollama API**: Local LLM deployment (optional)\n- **MCP Servers**: Dynamic tool providers via Model Context Protocol\n\n**Protocols:**\n- **HTTP/REST**: OpenAI and Ollama API communication via httpx\n- **MCP Protocol**: \n  - Stdio-based communication for local MCP servers\n  - SSE (Server-Sent Events) for remote MCP servers\n- **WebSocket**: Potential for real-time updates (Streamlit native)\n\n**Authentication:**\n- **API Keys**: OpenAI API key via environment variables\n- **Environment-based**: All credentials managed through .env files\n- **No built-in auth**: Local deployment model (future: add user authentication)\n\n### Monitoring & Dashboard Technologies\n\n**Dashboard Framework:**\n- **Streamlit**: Python-native web framework with reactive components\n- **Multi-page architecture**: Separate views for chat, settings, etc.\n- **Component-based UI**: Reusable message renderers and tool callbacks\n\n**Real-time Communication:**\n- **Async Execution**: Python asyncio for non-blocking agent execution\n- **Streaming Responses**: Real-time message streaming in chat interface\n- **Session Management**: Streamlit session state for conversation persistence\n\n**Visualization Libraries:**\n- **Rich**: Terminal-based formatting and progress indicators (CLI)\n- **Streamlit Components**: Native UI elements (chat messages, forms, metrics)\n\n**State Management:**\n- **Streamlit Session State**: In-memory state for web sessions\n- **ChatSession Class**: Manages conversation history and context\n- **File System**: Configuration as source of truth (YAML files)\n\n## Development Environment\n\n### Build & Development Tools\n\n- **Build System**: setuptools with pyproject.toml (PEP 621 compliant)\n- **Package Management**: \n  - **uv** (recommended): Fast, modern Python package manager\n  - **pip**: Fallback for traditional workflows\n- **Development workflow**: \n  - **Makefile**: Common commands (install, test, serve, clean)\n  - **Hot reload**: Streamlit auto-reload on file changes (`make serve-dev`)\n  - **REPL**: Python REPL with state persistence (repl_state.pkl)\n\n**Make Targets:**\n```bash\nmake install      # Install with dev dependencies\nmake install-min  # Runtime only\nmake test         # Run pytest suite\nmake serve        # Launch Streamlit web interface\nmake serve-dev    # Development mode with auto-reload\nmake clean        # Remove temporary files\n```\n\n### Code Quality Tools\n\n- **Static Analysis**: Ruff (fast Python linter)\n- **Formatting**: Ruff (replaces Black and isort)\n- **Testing Framework**: \n  - pytest for unit and integration tests\n  - pytest-asyncio for async test support\n  - pytest-cov for coverage reporting\n- **Documentation**: \n  - Markdown documentation in docs/\n  - Inline docstrings (Google style)\n  - README-driven development\n\n**Test Configuration:**\n- Suppress third-party deprecation warnings\n- Strict markers and config enforcement\n- Verbose output for debugging\n- Test discovery: `test_*.py` pattern\n\n### Version Control & Collaboration\n\n- **VCS**: Git\n- **Branching Strategy**: Feature branches with main as stable\n- **Code Review Process**: Pull requests with review before merge\n- **Repository Structure**: \n  - src/ layout for clean package structure\n  - Separate configs/, examples/, tests/, docs/\n\n### Dashboard Development\n\n- **Live Reload**: Streamlit watch mode with automatic rerun\n- **Port Management**: \n  - Default: localhost:8501\n  - Configurable via `--port` and `--host` flags\n- **Multi-Instance Support**: Can run multiple Streamlit instances on different ports\n- **Development Mode**: `make serve-dev` for enhanced debugging\n\n## Deployment & Distribution\n\n- **Target Platform(s)**: \n  - **Primary**: macOS, Linux (development and production)\n  - **Secondary**: Windows (community support)\n  - **Deployment**: Local installation, no cloud hosting required\n  \n- **Distribution Method**: \n  - **PyPI** (future): pip install fivcadvisor\n  - **Git Clone**: Direct repository installation\n  - **uv**: Fast installation via uv sync\n  \n- **Installation Requirements**: \n  - Python 3.10 or higher\n  - API keys for LLM providers (OpenAI or Ollama)\n  - Optional: Node.js for MCP tools (e.g., Playwright)\n  \n- **Update Mechanism**: \n  - Git pull for development\n  - pip/uv upgrade for package updates\n  - Lock file (uv.lock) ensures reproducible builds\n\n## Technical Requirements & Constraints\n\n### Performance Requirements\n\n- **Response Time**: \n  - CLI: < 100ms startup time\n  - Web UI: < 2s page load\n  - Agent execution: Depends on LLM latency (typically 2-10s)\n  \n- **Memory Usage**: \n  - Base: ~100MB for Python runtime\n  - ChromaDB: ~50-200MB depending on tool count\n  - Streamlit: ~50-100MB for web interface\n  \n- **Startup Time**: \n  - CLI: < 1s for simple commands\n  - Web UI: 2-5s for Streamlit initialization\n  - Tool loading: 1-3s for MCP client initialization\n\n### Compatibility Requirements  \n\n- **Platform Support**: \n  - macOS (primary development platform)\n  - Linux (Ubuntu 20.04+, Debian, Fedora)\n  - Windows (community support, may require WSL)\n  \n- **Dependency Versions**: \n  - Python: >=3.10 (required for modern type hints)\n  - Core dependencies: Minimum versions specified with >=\n  - Lock file ensures exact versions for reproducibility\n  \n- **Standards Compliance**: \n  - PEP 621: pyproject.toml metadata\n  - MCP Protocol: Model Context Protocol specification\n  - OpenAI API: Compatible with OpenAI API v1\n\n### Security & Compliance\n\n- **Security Requirements**: \n  - API keys stored in .env files (not committed to git)\n  - No built-in authentication (local deployment model)\n  - HTTPS for external API calls (OpenAI)\n  \n- **Compliance Standards**: \n  - No specific compliance requirements (general-purpose tool)\n  - User responsible for data handling in their use cases\n  \n- **Threat Model**: \n  - **Local execution**: Assumes trusted local environment\n  - **API key protection**: Users must secure their .env files\n  - **Code execution**: Python REPL tool can execute arbitrary code (use with caution)\n  - **MCP tools**: External tools run with user's permissions\n\n### Scalability & Reliability\n\n- **Expected Load**: \n  - Single-user local deployment\n  - 1-10 concurrent agent executions\n  - 10-100 tools in registry\n  \n- **Availability Requirements**: \n  - No uptime requirements (local tool)\n  - Graceful degradation if LLM API unavailable\n  \n- **Growth Projections**: \n  - Tool library: 50-200 tools over time\n  - Agent types: 10-20 specialized agents\n  - User base: Individual developers to small teams\n\n## Technical Decisions & Rationale\n\n### Decision Log\n\n1. **Strands Framework over CrewAI**\n   - **Why**: Strands provides cleaner abstractions and better MCP integration\n   - **Alternatives**: CrewAI (original), LangChain, AutoGen\n   - **Trade-offs**: Smaller community but more flexible architecture\n\n2. **Streamlit for Web UI**\n   - **Why**: Python-native, rapid development, built-in async support\n   - **Alternatives**: Flask/FastAPI + React, Gradio\n   - **Trade-offs**: Less customizable than React but much faster to develop\n\n3. **ChromaDB for Vector Storage**\n   - **Why**: Lightweight, embeddable, good Python integration\n   - **Alternatives**: Pinecone, Weaviate, FAISS\n   - **Trade-offs**: Limited scalability but perfect for local deployment\n\n4. **uv for Package Management**\n   - **Why**: 10-100x faster than pip, modern dependency resolution\n   - **Alternatives**: pip, poetry, pdm\n   - **Trade-offs**: Newer tool but significant performance benefits\n\n5. **MCP Protocol for Tool Integration**\n   - **Why**: Standard protocol, wide tool ecosystem, dynamic loading\n   - **Alternatives**: Custom tool API, LangChain tools\n   - **Trade-offs**: Requires MCP server setup but enables rich tool ecosystem\n\n6. **Decorator-based Agent Creation**\n   - **Why**: Clean API, type safety, easy registration\n   - **Alternatives**: Class-based factories, configuration files\n   - **Trade-offs**: More Python-specific but very ergonomic\n\n7. **YAML + .env for Configuration**\n   - **Why**: Human-readable, standard formats, environment separation\n   - **Alternatives**: TOML, JSON, pure Python\n   - **Trade-offs**: Requires parsing but widely understood\n\n## Known Limitations\n\n- **Single-user focus**: No multi-user support or authentication\n  - **Impact**: Cannot be deployed as shared service\n  - **Future**: Add user management and access control for team deployments\n\n- **Local deployment only**: No cloud hosting or remote access\n  - **Impact**: Users must run locally or manage their own hosting\n  - **Future**: Add tunnel features or cloud deployment options\n\n- **Limited tool generation**: Autonomous tool creation not yet implemented\n  - **Impact**: Users must manually add tools or use MCP servers\n  - **Future**: Implement Researcher + Engineer agent workflow for tool generation\n\n- **No persistent conversation history**: Sessions cleared on restart\n  - **Impact**: Cannot resume conversations across sessions\n  - **Future**: Add database-backed conversation storage\n\n- **Synchronous MCP initialization**: Tool loading blocks startup\n  - **Impact**: Slow startup with many MCP servers\n  - **Future**: Implement async tool loading and lazy initialization\n\n- **Limited error recovery**: Agent failures may require restart\n  - **Impact**: Poor user experience on errors\n  - **Future**: Add retry logic and graceful degradation\n\n",
  "fileStats": {
    "size": 15597,
    "lines": 375,
    "lastModified": "2025-10-10T03:11:26.378Z"
  },
  "comments": []
}